{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ad8539",
   "metadata": {},
   "source": [
    "# Amharic Text Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5dc8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60adf2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\python\\\\python310.zip', 'C:\\\\Program Files\\\\python\\\\DLLs', 'C:\\\\Program Files\\\\python\\\\lib', 'C:\\\\Program Files\\\\python', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\myenv', '', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\myenv\\\\lib\\\\site-packages', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\myenv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\myenv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\myenv\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\scripts', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\scripts', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\scripts', 'c:\\\\Users\\\\surap\\\\OneDrive\\\\Desktop\\\\10Acadamy\\\\Amharic-E-commerce\\\\scripts']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "print(sys.path)  # Check if the correct path is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c933b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add 'scripts' directory to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "\n",
    "# Import your classes\n",
    "from data_preprocessor import AmharicTextPreprocessor\n",
    "from data_labeler import AmharicLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e77919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "071e3760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 11:11:21,088 - INFO - âœ… Imported libraries and configured logging.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"âœ… Imported libraries and configured logging.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8809a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\surap\\OneDrive\\Desktop\\10Acadamy\\Amharic-E-commerce\\notebooks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1174b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded with shape: (500, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame using a relative path\n",
    "df = pd.read_csv('../data/Scraping data.csv')\n",
    "print(\"DataFrame loaded with shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16888acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " channel         0\n",
      "sender_id       0\n",
      "timestamp       0\n",
      "message       217\n",
      "views           1\n",
      "media_file      1\n",
      "dtype: int64\n",
      "Columns in the DataFrame: Index(['channel', 'sender_id', 'timestamp', 'message', 'views', 'media_file'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Let's check the missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "548e8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Amharic text: áŠ á‹µáˆ«áˆ»Â  á‰.1ğŸ‘‰ áˆµáˆª áŠ¤áˆ áˆ²á‰² áˆáˆ áˆáˆˆá‰°áŠ› áá‰… á‰¢áˆ® á‰. SL-05A(áŠ¨ áˆŠáá‰± áŠá‰µ áˆˆ áŠá‰µ)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Amharic text sample\n",
    "    amharic_text = \"áŠ á‹µáˆ«áˆ»Â  á‰.1ğŸ‘‰ áˆµáˆª áŠ¤áˆ áˆ²á‰² áˆáˆ áˆáˆˆá‰°áŠ› áá‰… á‰¢áˆ® á‰. SL-05A(áŠ¨ áˆŠáá‰± áŠá‰µ áˆˆ áŠá‰µ)\"\n",
    "    \n",
    "    print(\"Sample Amharic text:\", amharic_text)\n",
    "\n",
    "    preprocessor = AmharicTextPreprocessor()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25b91f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: Index(['channel', 'sender_id', 'timestamp', 'message', 'views', 'media_file'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "add327f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Amharic text: áŠ á‹µáˆ«áˆ»-áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ á•áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨áŒƒ áŠ¥áŠ•á‹°á‹ˆáŒ¡ 101 á‹¨á‰¢áˆ® á‰áŒ¥áˆ­ á‹«áŒˆáŠ™áŠ“áˆ\n",
      "Text preprocessing completed. Sample tokens:\n",
      "                      channel     sender_id                  timestamp  \\\n",
      "0  https://t.me/ZemenExpress -1.000000e+12  2025-06-18T06:01:10+00:00   \n",
      "1  https://t.me/ZemenExpress -1.000000e+12  2025-06-16T12:21:00+00:00   \n",
      "2  https://t.me/ZemenExpress -1.000000e+12  2025-06-16T05:11:57+00:00   \n",
      "3  https://t.me/ZemenExpress -1.000000e+12  2025-06-16T05:11:57+00:00   \n",
      "4  https://t.me/ZemenExpress -1.000000e+12  2025-06-16T05:11:57+00:00   \n",
      "\n",
      "                                             message   views  \\\n",
      "0  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...  1897.0   \n",
      "1  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...  3035.0   \n",
      "2                                                NaN  3104.0   \n",
      "3                                                NaN  3165.0   \n",
      "4                                                NaN  3129.0   \n",
      "\n",
      "                   media_file  \\\n",
      "0  ../data/raw/media/6982.mp4   \n",
      "1  ../data/raw/media/6981.mp4   \n",
      "2  ../data/raw/media/6980.jpg   \n",
      "3  ../data/raw/media/6979.jpg   \n",
      "4  ../data/raw/media/6978.jpg   \n",
      "\n",
      "                                preprocessed_message  \n",
      "0  á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­á‹¨áˆšáˆ°áˆ« áˆˆá‰¤á‰µ áˆ˜áˆáŠ«áˆ áˆ˜á‹“á‹›áŠ• á‹¨áˆšáˆ°áŒ¥ á‹‹áŒ‹ 1400 á‰¥áˆ­ á‹áˆµáŠ• ...  \n",
      "1  á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ á‹‹áŒ‹ 2400 á‰¥áˆ­ á‹áˆµ...  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Amharic text sample\n",
    "    amharic_text = \"áŠ á‹µáˆ«áˆ»-áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ á•áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨áŒƒ áŠ¥áŠ•á‹°á‹ˆáŒ¡ 101 á‹¨á‰¢áˆ® á‰áŒ¥áˆ­ á‹«áŒˆáŠ™áŠ“áˆ\"\n",
    "    print(\"Sample Amharic text:\", amharic_text)\n",
    "\n",
    "    preprocessor = AmharicTextPreprocessor()\n",
    "\n",
    "    # Preprocess the text\n",
    "    tokens = preprocessor.preprocess_dataframe(df, 'message')\n",
    "    print(\"Text preprocessing completed. Sample tokens:\\n\", tokens.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee1ad9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped NaN values from 'message'. New shape: (283, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Drop NaN values in 'messages' column\n",
    "df.dropna(subset='message', inplace=True)\n",
    "print(\"Dropped NaN values from 'message'. New shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3bc3b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed texts have been stored. New DataFrame shape: (282, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure there are no NaN values in the preprocessed column\n",
    "preprocessed_texts = tokens['preprocessed_message'].dropna().tolist()\n",
    "df = pd.Series(preprocessed_texts).reset_index(name='message')\n",
    "print(\"Preprocessed texts have been stored. New DataFrame shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "080830a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the labeler\n",
    "labeler = AmharicLabeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1c80884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed. Sample tokenized messages:\n",
      " 0    [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µ, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, á‹‹áŒ‹, 1400,...\n",
      "1    [á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, á‹«áˆµá‰½áˆá‹á‰³áˆ, á‹‹áŒ‹, 24...\n",
      "2    [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µáŠ“, áˆˆáˆ˜áŠªáŠ“, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, ...\n",
      "3    [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µáŠ“, áˆˆáˆ˜áŠªáŠ“, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, ...\n",
      "4    [á‹‹áŒ‹, 550, á‰¥áˆ­, á‹áˆµáŠ•, ááˆ¬, áŠá‹, á‹«áˆˆáŠ•, áŠ á‹µáˆ«áˆ», áˆ˜áŒˆáŠ“áŠ›áˆ˜áˆ°áˆ¨á‰µ...\n",
      "Name: Tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the messages\n",
    "df['Tokenized'] = df['message'].apply(lambda x: x.split())\n",
    "print(\"Tokenization completed. Sample tokenized messages:\\n\", df['Tokenized'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72e9a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling completed. Sample labeled DataFrame:\n",
      "    index                                            message  \\\n",
      "0      0  á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­á‹¨áˆšáˆ°áˆ« áˆˆá‰¤á‰µ áˆ˜áˆáŠ«áˆ áˆ˜á‹“á‹›áŠ• á‹¨áˆšáˆ°áŒ¥ á‹‹áŒ‹ 1400 á‰¥áˆ­ á‹áˆµáŠ• ...   \n",
      "1      1  á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ á‹‹áŒ‹ 2400 á‰¥áˆ­ á‹áˆµ...   \n",
      "2      2  á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­ á‹¨áˆšáˆ°áˆ« áˆˆá‰¤á‰µáŠ“ áˆˆáˆ˜áŠªáŠ“ áˆ˜áˆáŠ«áˆ áˆ˜á‹“á‹›áŠ• á‹¨áˆšáˆ°áŒ¥ á‹‹áŒ‹ 1100 ...   \n",
      "3      3  á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­ á‹¨áˆšáˆ°áˆ« áˆˆá‰¤á‰µáŠ“ áˆˆáˆ˜áŠªáŠ“ áˆ˜áˆáŠ«áˆ áˆ˜á‹“á‹›áŠ• á‹¨áˆšáˆ°áŒ¥ á‹‹áŒ‹ 1100 ...   \n",
      "4      4  á‹‹áŒ‹ 550 á‰¥áˆ­ á‹áˆµáŠ• ááˆ¬ áŠá‹ á‹«áˆˆáŠ• áŠ á‹µáˆ«áˆ» áˆ˜áŒˆáŠ“áŠ›áˆ˜áˆ°áˆ¨á‰µá‹°á‹áˆ­áˆáˆáˆáˆˆá‰°áŠ›...   \n",
      "\n",
      "                                           Tokenized  \\\n",
      "0  [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µ, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, á‹‹áŒ‹, 1400,...   \n",
      "1  [á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, á‹«áˆµá‰½áˆá‹á‰³áˆ, á‹‹áŒ‹, 24...   \n",
      "2  [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µáŠ“, áˆˆáˆ˜áŠªáŠ“, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, ...   \n",
      "3  [á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, á‹¨áˆšáˆ°áˆ«, áˆˆá‰¤á‰µáŠ“, áˆˆáˆ˜áŠªáŠ“, áˆ˜áˆáŠ«áˆ, áˆ˜á‹“á‹›áŠ•, á‹¨áˆšáˆ°áŒ¥, ...   \n",
      "4  [á‹‹áŒ‹, 550, á‰¥áˆ­, á‹áˆµáŠ•, ááˆ¬, áŠá‹, á‹«áˆˆáŠ•, áŠ á‹µáˆ«áˆ», áˆ˜áŒˆáŠ“áŠ›áˆ˜áˆ°áˆ¨á‰µ...   \n",
      "\n",
      "                                             Labeled  \n",
      "0  [(á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­á‹¨áˆšáˆ°áˆ«, O), (áˆˆá‰¤á‰µ, O), (áˆ˜áˆáŠ«áˆ, O), (áˆ˜á‹“á‹›áŠ•,...  \n",
      "1  [(á‰ áˆáˆˆáŒ‰á‰µ, O), (áŠ á‰…áŒ£áŒ«, O), (áˆáŒ…á‹áŠ•, O), (á‰ áˆá‰¾á‰µ, O), ...  \n",
      "2  [(á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, O), (á‹¨áˆšáˆ°áˆ«, O), (áˆˆá‰¤á‰µáŠ“, O), (áˆˆáˆ˜áŠªáŠ“, O)...  \n",
      "3  [(á‰ áŠ¤áˆŒáŠ­á‰µáˆªáŠ­, O), (á‹¨áˆšáˆ°áˆ«, O), (áˆˆá‰¤á‰µáŠ“, O), (áˆˆáˆ˜áŠªáŠ“, O)...  \n",
      "4  [(á‹‹áŒ‹, B-PRICE), (550, I-PRICE), (á‰¥áˆ­, I-PRICE),...  \n"
     ]
    }
   ],
   "source": [
    "# Label the tokens in the DataFrame\n",
    "labeled_df = labeler.label_dataframe(df, 'Tokenized')\n",
    "print(\"Labeling completed. Sample labeled DataFrame:\\n\", labeled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e1b15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Labeled data saved in CoNLL format.\n"
     ]
    }
   ],
   "source": [
    "# Save to CoNLL format\n",
    "labeler.save_conll_format(labeled_df, '../labeled_data.conll')\n",
    "print(\"âœ… Labeled data saved in CoNLL format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03d0b5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate messages in labeled DataFrame: 123\n"
     ]
    }
   ],
   "source": [
    "duplicates = labeled_df['message'].duplicated().sum()\n",
    "print(\"Number of duplicate messages in labeled DataFrame:\", duplicates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
