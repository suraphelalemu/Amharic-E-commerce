{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eb919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surap\\OneDrive\\Desktop\\10Acadamy\\Amharic-E-commerce\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in main execution: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../models/amharic-ner-model'. Use `repo_type` argument if needed.\n"
     ]
    }
   ],
   "source": [
    "# model_interpretability.py\n",
    "import shap\n",
    "from lime import lime_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from jinja2 import Template\n",
    "import os\n",
    "\n",
    "class NERInterpreter:\n",
    "    def __init__(self, model, tokenizer, label_list, id2label):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_list = label_list\n",
    "        self.id2label = id2label\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"ner\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            aggregation_strategy=\"simple\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "    \n",
    "    def _get_shap_explanation(self, text, max_length=128):\n",
    "        \"\"\"Simplified SHAP explanation that handles text boundaries\"\"\"\n",
    "        try:\n",
    "            # Truncate text to prevent index errors\n",
    "            text = text[:max_length]\n",
    "            \n",
    "            # Create a masker for the text\n",
    "            masker = shap.maskers.Text(self.tokenizer)\n",
    "            \n",
    "            # Define prediction function that returns entity presence (0/1)\n",
    "            def predict(texts):\n",
    "                outputs = []\n",
    "                for t in texts:\n",
    "                    # Get predictions for this text\n",
    "                    preds = self.ner_pipeline(t)\n",
    "                    \n",
    "                    # Create binary output (1 for entity, 0 for non-entity)\n",
    "                    output = np.zeros(len(t))\n",
    "                    for pred in preds:\n",
    "                        start = min(pred['start'], len(t)-1)\n",
    "                        end = min(pred['end'], len(t))\n",
    "                        output[start:end] = 1\n",
    "                    outputs.append(output)\n",
    "                return np.array(outputs)\n",
    "            \n",
    "            # Create explainer\n",
    "            explainer = shap.Explainer(predict, masker)\n",
    "            \n",
    "            # Compute SHAP values\n",
    "            shap_values = explainer([text])\n",
    "            \n",
    "            # Visualize\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            shap.plots.text(shap_values)\n",
    "            plt.title(f\"SHAP Explanation for: {text[:50]}...\" + (\"...\" if len(text) > 50 else \"\"))\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return shap_values\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SHAP explanation failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_lime_explanation(self, text, num_features=10):\n",
    "        \"\"\"More robust LIME explanation for NER\"\"\"\n",
    "        try:\n",
    "            # Define prediction function that returns class probabilities\n",
    "            def predict_proba(texts):\n",
    "                outputs = []\n",
    "                for t in texts:\n",
    "                    # Tokenize text\n",
    "                    inputs = self.tokenizer(\n",
    "                        t,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        max_length=128\n",
    "                    ).to(self.device)\n",
    "                    \n",
    "                    # Get model predictions\n",
    "                    with torch.no_grad():\n",
    "                        logits = self.model(**inputs).logits\n",
    "                    \n",
    "                    # Convert to probabilities and take mean across tokens\n",
    "                    probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                    outputs.append(probs.mean(axis=1)[0])  # Average across tokens\n",
    "                \n",
    "                return np.array(outputs)\n",
    "            \n",
    "            # Create explainer with simpler settings\n",
    "            explainer = lime_text.LimeTextExplainer(\n",
    "                class_names=self.label_list,\n",
    "                split_expression=lambda x: x.split(),\n",
    "                bow=False,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Explain instance with fewer samples for stability\n",
    "            exp = explainer.explain_instance(\n",
    "                text,\n",
    "                predict_proba,\n",
    "                num_features=min(num_features, len(text.split())),\n",
    "                top_labels=min(3, len(self.label_list)),\n",
    "                num_samples=50  # Reduced for stability\n",
    "            )\n",
    "            \n",
    "            # Show explanation\n",
    "            fig = exp.as_pyplot_figure()\n",
    "            plt.title(f\"LIME Explanation for: {text[:50]}...\" + (\"...\" if len(text) > 50 else \"\"))\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return exp\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"LIME explanation failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_difficult_cases(self, difficult_examples):\n",
    "        \"\"\"Analyze cases where the model struggles\"\"\"\n",
    "        case_analysis = []\n",
    "        \n",
    "        for i, (text, true_ents, pred_ents) in enumerate(difficult_examples):\n",
    "            print(f\"\\nAnalyzing case {i+1}/{len(difficult_examples)}...\")\n",
    "            \n",
    "            # Get explanations (handle None returns)\n",
    "            shap_values = self._get_shap_explanation(text)\n",
    "            lime_exp = self._get_lime_explanation(text)\n",
    "            \n",
    "            # Compare predictions with ground truth\n",
    "            analysis = {\n",
    "                \"text\": text,\n",
    "                \"true_entities\": true_ents,\n",
    "                \"predicted_entities\": pred_ents,\n",
    "                \"shap_values\": shap_values,\n",
    "                \"lime_explanation\": lime_exp,\n",
    "                \"error_type\": self._classify_error(true_ents, pred_ents)\n",
    "            }\n",
    "            case_analysis.append(analysis)\n",
    "        \n",
    "        return case_analysis\n",
    "\n",
    "    def _classify_error(self, true_ents, pred_ents):\n",
    "        \"\"\"Improved error classification\"\"\"\n",
    "        if not true_ents and not pred_ents:\n",
    "            return \"No entities\"\n",
    "        if not true_ents:\n",
    "            return \"False positives\"\n",
    "        if not pred_ents:\n",
    "            return \"Missed all entities\"\n",
    "            \n",
    "        true_set = {(e['start'], e['end'], e['entity_group']) for e in true_ents}\n",
    "        pred_set = {(e['start'], e['end'], e['entity_group']) for e in pred_ents}\n",
    "        \n",
    "        if true_set == pred_set:\n",
    "            return \"Correct prediction\"\n",
    "        \n",
    "        if not true_set.intersection(pred_set):\n",
    "            return \"Completely wrong prediction\"\n",
    "        \n",
    "        if len(pred_set) > len(true_set):\n",
    "            return \"Over-prediction\"\n",
    "        \n",
    "        if len(pred_set) < len(true_set):\n",
    "            return \"Under-prediction\"\n",
    "        \n",
    "        return \"Partial match\"\n",
    "\n",
    "    def generate_report(self, case_analyses, output_file=\"interpretability_report.html\"):\n",
    "        \"\"\"Generate HTML report with error handling\"\"\"\n",
    "        if not case_analyses:\n",
    "            print(\"No cases to analyze\")\n",
    "            return None\n",
    "            \n",
    "        # Create output directory if needed\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        # Prepare data for report\n",
    "        error_counts = defaultdict(int)\n",
    "        cases_for_report = []\n",
    "        \n",
    "        for case in case_analyses:\n",
    "            error_counts[case['error_type']] += 1\n",
    "            \n",
    "            # Generate observations\n",
    "            observations = []\n",
    "            if case['error_type'] != \"Correct prediction\":\n",
    "                observations.append(f\"Model made '{case['error_type']}' error\")\n",
    "            \n",
    "            if case.get('shap_values'):\n",
    "                observations.append(\"SHAP analysis available\")\n",
    "            \n",
    "            if case.get('lime_explanation'):\n",
    "                observations.append(\"LIME analysis available\")\n",
    "            \n",
    "            cases_for_report.append({\n",
    "                \"text\": case['text'],\n",
    "                \"true_entities\": case['true_entities'],\n",
    "                \"predicted_entities\": case['predicted_entities'],\n",
    "                \"error_type\": case['error_type'],\n",
    "                \"observations\": observations\n",
    "            })\n",
    "        \n",
    "        # Generate HTML\n",
    "        template = Template(\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>NER Model Interpretability Report</title>\n",
    "            <style>\n",
    "                body { font-family: Arial, sans-serif; margin: 2em; }\n",
    "                table { border-collapse: collapse; width: 100%; }\n",
    "                th, td { border: 1px solid #ddd; padding: 8px; }\n",
    "                th { background-color: #f2f2f2; }\n",
    "                .error { color: #d9534f; font-weight: bold; }\n",
    "                .correct { color: #5cb85c; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>NER Model Interpretability Report</h1>\n",
    "            <p>Generated on {{ date }}</p>\n",
    "            \n",
    "            <h2>Summary</h2>\n",
    "            <p>Analyzed {{ cases|length }} cases with the following results:</p>\n",
    "            <ul>\n",
    "                {% for error, count in error_counts.items() %}\n",
    "                <li>{{ error }}: {{ count }} cases</li>\n",
    "                {% endfor %}\n",
    "            </ul>\n",
    "            \n",
    "            <h2>Detailed Cases</h2>\n",
    "            {% for case in cases %}\n",
    "            <div style=\"margin-bottom: 3em; padding: 1em; border: 1px solid #eee;\">\n",
    "                <h3 class=\"{% if case.error_type == 'Correct prediction' %}correct{% else %}error{% endif %}\">\n",
    "                    Case {{ loop.index }}: {{ case.error_type }}\n",
    "                </h3>\n",
    "                <p><strong>Text:</strong> {{ case.text }}</p>\n",
    "                \n",
    "                <table>\n",
    "                    <tr>\n",
    "                        <th>True Entities</th>\n",
    "                        <th>Predicted Entities</th>\n",
    "                    </tr>\n",
    "                    <tr>\n",
    "                        <td>\n",
    "                            {% if case.true_entities %}\n",
    "                            <ul>\n",
    "                                {% for ent in case.true_entities %}\n",
    "                                <li>{{ ent.entity_group }} ({{ ent.start }}-{{ ent.end }}): \"{{ case.text[ent.start:ent.end] }}\"</li>\n",
    "                                {% endfor %}\n",
    "                            </ul>\n",
    "                            {% else %}\n",
    "                            <p>No true entities</p>\n",
    "                            {% endif %}\n",
    "                        </td>\n",
    "                        <td>\n",
    "                            {% if case.predicted_entities %}\n",
    "                            <ul>\n",
    "                                {% for ent in case.predicted_entities %}\n",
    "                                <li>{{ ent.entity_group }} ({{ ent.start }}-{{ ent.end }}): \"{{ case.text[ent.start:ent.end] }}\"</li>\n",
    "                                {% endfor %}\n",
    "                            </ul>\n",
    "                            {% else %}\n",
    "                            <p>No predicted entities</p>\n",
    "                            {% endif %}\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                </table>\n",
    "                \n",
    "                <h4>Analysis</h4>\n",
    "                <ul>\n",
    "                    {% for obs in case.observations %}\n",
    "                    <li>{{ obs }}</li>\n",
    "                    {% else %}\n",
    "                    <li>No additional analysis available</li>\n",
    "                    {% endfor %}\n",
    "                </ul>\n",
    "            </div>\n",
    "            {% endfor %}\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\")\n",
    "        \n",
    "        html = template.render(\n",
    "            date=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            cases=cases_for_report,\n",
    "            error_counts=dict(error_counts)\n",
    "        )\n",
    "        \n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"Report generated at: {output_file}\")\n",
    "        return output_file\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage with proper error handling\"\"\"\n",
    "    try:\n",
    "        # Initialize model\n",
    "        model_path = \"../models/amharic-ner-model\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "        \n",
    "        # Define labels\n",
    "        label_list = [\"O\", \"B-PRODUCT\", \"I-PRODUCT\", \"B-PRICE\", \"I-PRICE\", \"B-LOC\", \"I-LOC\"]\n",
    "        id2label = {i: l for i, l in enumerate(label_list)}\n",
    "        \n",
    "        # Create interpreter\n",
    "        interpreter = NERInterpreter(model, tokenizer, label_list, id2label)\n",
    "        \n",
    "        # Example cases with proper entity boundaries\n",
    "        difficult_cases = [\n",
    "            (\n",
    "                \"ልብስ በ 500 ብር ከ አዲስ አበባ\",\n",
    "                [\n",
    "                    {\"entity_group\": \"PRODUCT\", \"start\": 0, \"end\": 5, \"word\": \"ልብስ\"},\n",
    "                    {\"entity_group\": \"PRICE\", \"start\": 6, \"end\": 13, \"word\": \"500 ብር\"},\n",
    "                    {\"entity_group\": \"LOC\", \"start\": 17, \"end\": 27, \"word\": \"አዲስ አበባ\"}\n",
    "                ],\n",
    "                interpreter.ner_pipeline(\"ልብስ በ 500 ብር ከ አዲስ አበባ\")\n",
    "            ),\n",
    "            (\n",
    "                \"በ 200 ብር አዲስ ልብስ\",\n",
    "                [\n",
    "                    {\"entity_group\": \"PRICE\", \"start\": 2, \"end\": 10, \"word\": \"200 ብር\"},\n",
    "                    {\"entity_group\": \"PRODUCT\", \"start\": 11, \"end\": 16, \"word\": \"ልብስ\"}\n",
    "                ],\n",
    "                interpreter.ner_pipeline(\"በ 200 ብር አዲስ ልብስ\")\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Analyze cases\n",
    "        case_analyses = interpreter.analyze_difficult_cases(difficult_cases)\n",
    "        \n",
    "        # Generate report\n",
    "        if case_analyses:\n",
    "            report_path = interpreter.generate_report(\n",
    "                case_analyses,\n",
    "                output_file=\"../reports/ner_interpretability_report.html\"\n",
    "            )\n",
    "            print(f\"Analysis complete. Report saved to: {report_path}\")\n",
    "        else:\n",
    "            print(\"Analysis completed but no cases were successfully processed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
